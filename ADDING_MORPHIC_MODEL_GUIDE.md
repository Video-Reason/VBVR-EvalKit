# æ·»åŠ  Morphic æ¨¡å‹åˆ° VMEvalKit - å®Œæ•´æŒ‡å—

## ğŸ“‹ ä»»åŠ¡æ¦‚è¿°

å°† Morphic Frames-to-Video æ¨¡å‹é›†æˆåˆ° VMEvalKit æ¡†æ¶ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåƒå…¶ä»–æ¨¡å‹ä¸€æ ·å‚ä¸æ¨ç†æµ‹è¯•ï¼ˆchessã€mazeã€sudokuã€rotationã€raven ç­‰ä»»åŠ¡ï¼‰ã€‚

## ğŸ¯ ç›®æ ‡

å®Œæˆä»¥ä¸‹å·¥ä½œï¼Œä½¿ Morphic æ¨¡å‹èƒ½å¤Ÿï¼š
1. é€šè¿‡ `examples/generate_videos.py` è¿è¡Œæ¨ç†
2. å¤„ç†æ‰€æœ‰ä»»åŠ¡ç±»å‹ï¼ˆchessã€mazeã€sudokuã€rotationã€ravenï¼‰
3. ç”Ÿæˆç¬¦åˆ VMEvalKit æ ¼å¼çš„è§†é¢‘è¾“å‡º
4. å‚ä¸è¯„åˆ†å’Œè¯„ä¼°æµç¨‹
5. åœ¨ Web Dashboard ä¸­æ˜¾ç¤ºç»“æœ

---

## ğŸ“ å®æ–½æ­¥éª¤

### é˜¶æ®µä¸€ï¼šæ·»åŠ  Submodule

#### æ­¥éª¤ 1.1ï¼šæ·»åŠ  Morphic ä½œä¸º Git Submodule

```bash
cd /Users/maiwang/VMEvalKit-feature-add-morphic
git submodule add https://github.com/morphicfilms/frames-to-video.git submodules/morphic-frames-to-video
```

**éªŒè¯**ï¼šæ£€æŸ¥ `submodules/morphic-frames-to-video/` ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œå¹¶åŒ…å« `generate.py` æ–‡ä»¶ã€‚

---

### é˜¶æ®µäºŒï¼šå®ç°æ ¸å¿ƒä»£ç 

#### æ­¥éª¤ 2.1ï¼šå®Œå–„ `morphic_inference.py`

**æ–‡ä»¶ä½ç½®**ï¼š`vmevalkit/models/morphic_inference.py`

**å½“å‰çŠ¶æ€**ï¼šåªæœ‰æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œéœ€è¦å®Œæ•´å®ç°ã€‚

**å‚è€ƒæ–‡ä»¶**ï¼š
- `vmevalkit/models/hunyuan_inference.py` - subprocess æ¨¡å¼å‚è€ƒ
- `vmevalkit/models/videocrafter_inference.py` - å¤æ‚å‘½ä»¤æ„å»ºå‚è€ƒ
- `vmevalkit/models/base.py` - æ¥å£å®šä¹‰

**éœ€è¦å®ç°çš„ç±»å’Œæ–¹æ³•**ï¼š

1. **MorphicService ç±»**
   ```python
   class MorphicService:
       def __init__(self, model_id, output_dir, **kwargs):
           # 1. å®šä¹‰ submodule è·¯å¾„
           # 2. æ£€æŸ¥ submodule æ˜¯å¦å­˜åœ¨
           # 3. ä»ç¯å¢ƒå˜é‡æˆ– kwargs è¯»å–æƒé‡è·¯å¾„
           # 4. éªŒè¯æƒé‡è·¯å¾„å­˜åœ¨
           # 5. åˆå§‹åŒ–é…ç½®å‚æ•°
       
       def _validate_paths(self):
           # éªŒè¯æ‰€æœ‰å¿…éœ€è·¯å¾„å­˜åœ¨
           # - submodules/morphic-frames-to-video/generate.py
           # - Wan2.2 æƒé‡ç›®å½•
           # - LoRA æƒé‡æ–‡ä»¶
       
       def _run_morphic_inference(self, image_path, text_prompt, final_image_path, **kwargs):
           # 1. æ„å»º torchrun å‘½ä»¤
           # 2. ä½¿ç”¨ subprocess æ‰§è¡Œ
           # 3. å¤„ç†è¾“å‡ºå’Œé”™è¯¯
           # 4. è¿”å›æ ‡å‡†æ ¼å¼ç»“æœ
       
       def generate(self, image_path, text_prompt, duration, output_filename, **kwargs):
           # ç»Ÿä¸€æ¥å£ï¼Œè°ƒç”¨ _run_morphic_inference
   ```

2. **MorphicWrapper ç±»**
   ```python
   class MorphicWrapper(ModelWrapper):
       def __init__(self, model, output_dir, **kwargs):
           # åˆå§‹åŒ– wrapperï¼Œåˆ›å»º MorphicService å®ä¾‹
       
       def generate(self, image_path, text_prompt, duration, output_filename, **kwargs):
           # å®ç° ModelWrapper æ¥å£
           # ä» kwargs æˆ– question_data è·å– final_image_path
           # è°ƒç”¨ service.generate()
           # è¿”å›æ ‡å‡†æ ¼å¼ç»“æœ
   ```

**å…³é”®å®ç°ç‚¹**ï¼š

1. **è·¯å¾„å®šä¹‰**ï¼š
   ```python
   MORPHIC_PATH = Path(__file__).parent.parent.parent / "submodules" / "morphic-frames-to-video"
   ```

2. **è·å– final_image_path**ï¼š
   ```python
   question_data = kwargs.get('question_data', {})
   final_image_path = question_data.get('final_image_path')
   if not final_image_path:
       # é”™è¯¯å¤„ç†æˆ– fallback
   ```

3. **æ„å»º torchrun å‘½ä»¤**ï¼š
   ```python
   cmd = [
       "torchrun",
       f"--nproc_per_node={nproc}",
       str(MORPHIC_PATH / "generate.py"),
       "--task", "i2v-A14B",
       "--size", "1280*720",
       "--frame_num", "81",
       "--ckpt_dir", wan2_ckpt_dir,
       "--high_noise_lora_weights_path", lora_weights_path,
       "--dit_fsdp",
       "--t5_fsdp",
       "--ulysses_size", "8",
       "--image", str(image_path),
       "--prompt", text_prompt,
       "--img_end", str(final_image_path),
   ]
   ```

4. **æ‰§è¡Œ subprocess**ï¼š
   ```python
   result = subprocess.run(
       cmd,
       cwd=str(MORPHIC_PATH),
       capture_output=True,
       text=True,
       timeout=900  # 15åˆ†é’Ÿè¶…æ—¶
   )
   ```

5. **è¿”å›æ ‡å‡†æ ¼å¼**ï¼š
   ```python
   return {
       "success": bool,
       "video_path": str | None,
       "error": str | None,
       "duration_seconds": float,
       "generation_id": str,
       "model": str,
       "status": str,
       "metadata": dict
   }
   ```

---

### é˜¶æ®µä¸‰ï¼šæ³¨å†Œæ¨¡å‹

#### æ­¥éª¤ 3.1ï¼šåœ¨ `MODEL_CATALOG.py` ä¸­æ·»åŠ æ¨¡å‹å®šä¹‰

**æ–‡ä»¶ä½ç½®**ï¼š`vmevalkit/runner/MODEL_CATALOG.py`

**åœ¨ "OPEN-SOURCE MODELS (SUBMODULES)" éƒ¨åˆ†æ·»åŠ **ï¼š

```python
# Morphic Frames-to-Video Models
MORPHIC_MODELS = {
    "morphic-frames-to-video": {
        "wrapper_module": "vmevalkit.models.morphic_inference",
        "wrapper_class": "MorphicWrapper",
        "service_class": "MorphicService",
        "model": "morphic-frames-to-video",
        "description": "Morphic Frames to Video - High-quality interpolation using Wan2.2",
        "family": "Morphic",
        "args": {
            "size": "1280*720",
            "frame_num": 81,
            "nproc_per_node": 8
        }
    }
}
```

**åœ¨æ–‡ä»¶åº•éƒ¨åˆå¹¶åˆ°ç»Ÿä¸€æ³¨å†Œè¡¨**ï¼š

```python
AVAILABLE_MODELS = {
    **LUMA_MODELS,
    **VEO_MODELS,
    # ... å…¶ä»–æ¨¡å‹
    **MORPHIC_MODELS,  # æ·»åŠ è¿™ä¸€è¡Œ
    # ... å…¶ä»–æ¨¡å‹
}

MODEL_FAMILIES = {
    "Luma Dream Machine": LUMA_MODELS,
    # ... å…¶ä»–å®¶æ—
    "Morphic": MORPHIC_MODELS,  # æ·»åŠ è¿™ä¸€è¡Œ
    # ... å…¶ä»–å®¶æ—
}
```

#### æ­¥éª¤ 3.2ï¼šæ›´æ–° `models/__init__.py`

**æ–‡ä»¶ä½ç½®**ï¼š`vmevalkit/models/__init__.py`

**åœ¨ `__all__` åˆ—è¡¨ä¸­æ·»åŠ **ï¼š
```python
"MorphicService", "MorphicWrapper",
```

**åœ¨ `_MODULE_MAP` å­—å…¸ä¸­æ·»åŠ **ï¼š
```python
"morphic_inference": ["MorphicService", "MorphicWrapper"],
```

---

### é˜¶æ®µå››ï¼šé…ç½®ç¯å¢ƒå˜é‡

#### æ­¥éª¤ 4.1ï¼šæ›´æ–° `env.template`

**æ–‡ä»¶ä½ç½®**ï¼š`env.template`

**æ·»åŠ  Morphic ç›¸å…³é…ç½®**ï¼š
```bash
# Morphic Frames-to-Video Configuration
MORPHIC_WAN2_CKPT_DIR=./Wan2.2-I2V-A14B
MORPHIC_LORA_WEIGHTS_PATH=./morphic-frames-lora-weights/lora_interpolation_high_noise_final.safetensors
MORPHIC_NPROC_PER_NODE=8
```

---

### é˜¶æ®µäº”ï¼šæµ‹è¯•éªŒè¯

#### æ­¥éª¤ 5.1ï¼šåŸºç¡€åŠŸèƒ½æµ‹è¯•

```bash
# æµ‹è¯•æ¨¡å‹æ³¨å†Œ
python -c "from vmevalkit.runner.MODEL_CATALOG import AVAILABLE_MODELS; print('morphic-frames-to-video' in AVAILABLE_MODELS)"

# æµ‹è¯•åŠ¨æ€åŠ è½½
python -c "from vmevalkit.runner.inference import _load_model_wrapper; wrapper = _load_model_wrapper('morphic-frames-to-video'); print(wrapper)"
```

#### æ­¥éª¤ 5.2ï¼šå•ä»»åŠ¡æ¨ç†æµ‹è¯•

```bash
# ç¡®ä¿æœ‰æµ‹è¯•æ•°æ®
python examples/create_questions.py --task chess --pairs-per-domain 1

# æµ‹è¯•å•ä¸ªä»»åŠ¡
python examples/generate_videos.py --model morphic-frames-to-video --task-id chess_0000
```

#### æ­¥éª¤ 5.3ï¼šæ‰¹é‡ä»»åŠ¡æµ‹è¯•

```bash
# æµ‹è¯•å•ä¸ªåŸŸ
python examples/generate_videos.py --model morphic-frames-to-video --task chess

# æµ‹è¯•å¤šä¸ªåŸŸ
python examples/generate_videos.py --model morphic-frames-to-video --task chess maze
```

---

## ğŸ”‘ å…³é”®æ³¨æ„äº‹é¡¹

### 1. final_image_path å¤„ç†

Morphic æ¨¡å‹éœ€è¦ä¸¤ä¸ªå›¾åƒè¾“å…¥ï¼š
- `--image`ï¼šèµ·å§‹å¸§ï¼ˆVMEvalKit çš„ `first_frame.png`ï¼‰
- `--img_end`ï¼šç»“æŸå¸§ï¼ˆVMEvalKit çš„ `final_frame.png`ï¼‰

**è·å–æ–¹å¼**ï¼š
```python
# åœ¨ MorphicWrapper.generate() ä¸­
question_data = kwargs.get('question_data', {})
final_image_path = question_data.get('final_image_path')

if not final_image_path:
    return {
        "success": False,
        "error": "Morphic requires final_image_path in question_data",
        # ... å…¶ä»–å¿…éœ€å­—æ®µ
    }
```

### 2. æƒé‡è·¯å¾„é…ç½®

æƒé‡è·¯å¾„é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼š
```python
wan2_ckpt_dir = os.getenv(
    "MORPHIC_WAN2_CKPT_DIR",
    "./Wan2.2-I2V-A14B"  # é»˜è®¤è·¯å¾„
)

lora_weights_path = os.getenv(
    "MORPHIC_LORA_WEIGHTS_PATH",
    "./morphic-frames-lora-weights/lora_interpolation_high_noise_final.safetensors"
)
```

### 3. GPU è¦æ±‚

Morphic ä½¿ç”¨ `torchrun --nproc_per_node=8`ï¼Œéœ€è¦ 8 ä¸ª GPUã€‚å¦‚æœ GPU ä¸è¶³ï¼š
- å¯ä»¥å°è¯• `--nproc_per_node=1`ï¼ˆå• GPUï¼‰
- æˆ–åœ¨åˆå§‹åŒ–æ—¶æ£€æŸ¥ GPU æ•°é‡å¹¶ç»™å‡ºæ¸…æ™°é”™è¯¯æç¤º

### 4. é”™è¯¯å¤„ç†

ç¡®ä¿æ‰€æœ‰é”™è¯¯åœºæ™¯éƒ½æœ‰å¤„ç†ï¼š
- Submodule ä¸å­˜åœ¨
- æƒé‡è·¯å¾„ä¸å­˜åœ¨
- GPU æ•°é‡ä¸è¶³
- final_image_path ä¸å­˜åœ¨
- torchrun æ‰§è¡Œå¤±è´¥
- è¶…æ—¶

### 5. è¾“å‡ºè·¯å¾„

ç¡®ä¿ç”Ÿæˆçš„è§†é¢‘ä¿å­˜åˆ° `self.output_dir`ï¼Œå¹¶ä¸”è·¯å¾„æ­£ç¡®ã€‚

---

## ğŸ“š å‚è€ƒå®ç°

### ç±»ä¼¼æ¨¡å‹å®ç°å‚è€ƒ

1. **HunyuanVideo** (`hunyuan_inference.py`)
   - ä½¿ç”¨ subprocess è°ƒç”¨ Python è„šæœ¬
   - ç®€å•çš„å‘½ä»¤æ„å»º

2. **VideoCrafter** (`videocrafter_inference.py`)
   - å¤æ‚çš„å‘½ä»¤æ„å»º
   - ä¸´æ—¶è„šæœ¬åˆ›å»º

3. **WAN** (`wan_inference.py`)
   - ç›´æ¥ Python è°ƒç”¨ï¼ˆä¸æ˜¯ subprocessï¼‰
   - æ³¨æ„ï¼šWAN æœ‰ `last_image` å‚æ•°ï¼Œä½†å®é™…ä¼ å…¥çš„æ˜¯åŒä¸€ä¸ªå›¾åƒ

### æ¥å£è§„èŒƒå‚è€ƒ

æŸ¥çœ‹ `vmevalkit/models/base.py` ä¸­çš„ `ModelWrapper` æŠ½è±¡åŸºç±»ï¼Œç¡®ä¿å®ç°ç¬¦åˆæ¥å£è¦æ±‚ã€‚

---

## âœ… å®Œæˆæ£€æŸ¥æ¸…å•

- [ ] Submodule å·²æ·»åŠ 
- [ ] `morphic_inference.py` å®Œæ•´å®ç°
- [ ] `MorphicService` ç±»å®ç°å®Œæ•´
- [ ] `MorphicWrapper` ç±»å®ç°å®Œæ•´
- [ ] æ‰€æœ‰æ–¹æ³•éƒ½æœ‰é”™è¯¯å¤„ç†
- [ ] è¿”å›æ ¼å¼ç¬¦åˆ `ModelWrapper` æ¥å£
- [ ] `MODEL_CATALOG.py` ä¸­å·²æ³¨å†Œ
- [ ] `models/__init__.py` ä¸­å·²å¯¼å‡º
- [ ] `env.template` ä¸­å·²æ·»åŠ é…ç½®
- [ ] åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡
- [ ] å•ä»»åŠ¡æ¨ç†æµ‹è¯•é€šè¿‡
- [ ] æ‰¹é‡ä»»åŠ¡æµ‹è¯•é€šè¿‡

---

## ğŸš€ å¼€å§‹å®æ–½

æŒ‰ç…§ä»¥ä¸Šæ­¥éª¤é€æ­¥å®æ–½ï¼Œæ¯å®Œæˆä¸€ä¸ªé˜¶æ®µå°±è¿›è¡Œæµ‹è¯•éªŒè¯ï¼Œç¡®ä¿åŠŸèƒ½æ­£å¸¸åå†ç»§ç»­ä¸‹ä¸€æ­¥ã€‚

å¦‚æœåœ¨å®æ–½è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå‚è€ƒç°æœ‰æ¨¡å‹çš„å®ç°ï¼Œæˆ–æŸ¥çœ‹ VMEvalKit çš„æ–‡æ¡£ã€‚

